apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: training-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.4.0, pipelines.kubeflow.org/pipeline_compilation_time: '2021-03-04T22:49:15.505359',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Sample training job test",
      "inputs": [{"default": "/pvc/input", "name": "input_directory", "optional":
      true}, {"default": "/pvc/output", "name": "output_directory", "optional": true},
      {"default": "image_classifier", "name": "handlerFile", "optional": true}], "name":
      "Training pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.4.0}
spec:
  entrypoint: training-pipeline
  templates:
  - name: preprocessdata
    container:
      args: [--input_data, '[{"dataset_url": "https://kubeflow-dataset.s3.us-east-2.amazonaws.com/ag_news_csv.tar.gz"}]',
        --container_entrypoint, '["python", "/pvc/input/bert_pre_process.py"]', --output_data,
        '["/pvc/output/processing"]', --source_code, '["https://kubeflow-dataset.s3.us-east-2.amazonaws.com/bert_pre_process.py"]',
        --source_code_path, '["/pvc/input"]']
      command: [python3, /component/data_prep/src/data_prep_process.py]
      image: jagadeeshj/testingbert:04-03-2021-22-48-00.680888
      volumeMounts:
      - {mountPath: /pvc, name: volume-creation}
    inputs:
      parameters:
      - {name: volume-creation-name}
    volumes:
    - name: volume-creation
      persistentVolumeClaim: {claimName: '{{inputs.parameters.volume-creation-name}}'}
    metadata:
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Prepare
          data for PyTorch training.\n", "implementation": {"container": {"args":
          ["--input_data", {"inputValue": "input_data"}, "--container_entrypoint",
          {"inputValue": "container_entrypoint"}, "--output_data", {"inputValue":
          "output_data"}, "--source_code", {"inputValue": "source_code"}, "--source_code_path",
          {"inputValue": "source_code_path"}], "command": ["python3", "/component/data_prep/src/data_prep_process.py"],
          "image": "jagadeeshj/testingbert:04-03-2021-22-48-00.680888"}}, "inputs":
          [{"description": "The path to the input datasets", "name": "input_data",
          "type": "JsonArray"}, {"default": "[]", "description": "The entrypoint for
          the processing job. This is in the form of a list of strings that make a
          command.", "name": "container_entrypoint", "type": "JsonArray"}, {"description":
          "The path to the input datasets", "name": "output_data", "type": "JsonArray"},
          {"description": "S3 path to download code", "name": "source_code", "type":
          "JsonArray"}, {"description": "local path to store the source code", "name":
          "source_code_path", "type": "JsonArray"}], "name": "PreProcessData"}', pipelines.kubeflow.org/component_ref: '{"digest":
          "8519ab3fb27c380c2bd8cf8d110978c9ac75cdfe2e1ae5eda5444b1bce1a7c93", "url":
          "bert/../pytorch/data_prep/component.yaml"}', pipelines.kubeflow.org/arguments.parameters: '{"container_entrypoint":
          "[\"python\", \"/pvc/input/bert_pre_process.py\"]", "input_data": "[{\"dataset_url\":
          \"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/ag_news_csv.tar.gz\"}]",
          "output_data": "[\"/pvc/output/processing\"]", "source_code": "[\"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/bert_pre_process.py\"]",
          "source_code_path": "[\"/pvc/input\"]"}'}
  - name: training
    container:
      args: [--input_data, '["/pvc/output/processing"]', --container_entrypoint, '["python",
          "/pvc/input/bert_train.py"]', --output_data, '["/pvc/output/train/models"]',
        --input_parameters, '[{"accelerator": null, "batch_size": 4, "learning_rate":
          0.001, "max_epochs": 1, "num_samples": 150, "num_workers": 1, "tensorboard_root":
          "/pvc/output/train/tensorboard"}]', --source_code, '["https://kubeflow-dataset.s3.us-east-2.amazonaws.com/bert_train.py"]',
        --source_code_path, '["/pvc/input"]']
      command: [python3, /component/train/src/train_process.py]
      image: jagadeeshj/testingbert:04-03-2021-22-48-00.680888
      volumeMounts:
      - {mountPath: /pvc, name: volume-creation}
    inputs:
      parameters:
      - {name: volume-creation-name}
    volumes:
    - name: volume-creation
      persistentVolumeClaim: {claimName: '{{inputs.parameters.volume-creation-name}}'}
    metadata:
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Pytorch
          training\n", "implementation": {"container": {"args": ["--input_data", {"inputValue":
          "input_data"}, "--container_entrypoint", {"inputValue": "container_entrypoint"},
          "--output_data", {"inputValue": "output_data"}, "--input_parameters", {"inputValue":
          "input_parameters"}, "--source_code", {"inputValue": "source_code"}, "--source_code_path",
          {"inputValue": "source_code_path"}], "command": ["python3", "/component/train/src/train_process.py"],
          "image": "jagadeeshj/testingbert:04-03-2021-22-48-00.680888"}}, "inputs":
          [{"description": "The path to the input datasets", "name": "input_data",
          "type": "JsonArray"}, {"default": "[]", "description": "The entrypoint for
          the processing job. This is in the form of a list of strings that make a
          command.", "name": "container_entrypoint", "type": "JsonArray"}, {"description":
          "The path to the input datasets", "name": "output_data", "type": "JsonArray"},
          {"description": "Configurable input parameters", "name": "input_parameters",
          "type": "JsonArray"}, {"description": "S3 path to download code", "name":
          "source_code", "type": "JsonArray"}, {"description": "local path to download
          code", "name": "source_code_path", "type": "JsonArray"}], "name": "Training"}',
        pipelines.kubeflow.org/component_ref: '{"digest": "67fa6871421f42fccf4b6c34ed1ee8ccdbce340665678c81298d6c9e130f7398",
          "url": "bert/../pytorch/train/component.yaml"}', pipelines.kubeflow.org/arguments.parameters: '{"container_entrypoint":
          "[\"python\", \"/pvc/input/bert_train.py\"]", "input_data": "[\"/pvc/output/processing\"]",
          "input_parameters": "[{\"accelerator\": null, \"batch_size\": 4, \"learning_rate\":
          0.001, \"max_epochs\": 1, \"num_samples\": 150, \"num_workers\": 1, \"tensorboard_root\":
          \"/pvc/output/train/tensorboard\"}]", "output_data": "[\"/pvc/output/train/models\"]",
          "source_code": "[\"https://kubeflow-dataset.s3.us-east-2.amazonaws.com/bert_train.py\"]",
          "source_code_path": "[\"/pvc/input\"]"}'}
  - name: training-pipeline
    dag:
      tasks:
      - name: preprocessdata
        template: preprocessdata
        dependencies: [volume-creation]
        arguments:
          parameters:
          - {name: volume-creation-name, value: '{{tasks.volume-creation.outputs.parameters.volume-creation-name}}'}
      - name: training
        template: training
        dependencies: [preprocessdata, volume-creation]
        arguments:
          parameters:
          - {name: volume-creation-name, value: '{{tasks.volume-creation.outputs.parameters.volume-creation-name}}'}
      - {name: volume-creation, template: volume-creation}
  - name: volume-creation
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: '{{workflow.name}}-pvcm'
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
    outputs:
      parameters:
      - name: volume-creation-manifest
        valueFrom: {jsonPath: '{}'}
      - name: volume-creation-name
        valueFrom: {jsonPath: '{.metadata.name}'}
      - name: volume-creation-size
        valueFrom: {jsonPath: '{.status.capacity.storage}'}
  arguments:
    parameters:
    - {name: input_directory, value: /pvc/input}
    - {name: output_directory, value: /pvc/output}
    - {name: handlerFile, value: image_classifier}
  serviceAccountName: pipeline-runner
